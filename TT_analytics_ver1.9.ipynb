{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TT data analytics by RV ver1.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings libraries\n",
    "##### please run the folowing cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from IPython.display import Javascript\n",
    "#Javascript(\"Jupyter.notebook.execute_cells([2,3])\")\n",
    "from IPython.display import IFrame\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import FileUpload\n",
    "from IPython.display import Javascript\n",
    "from ipyfilechooser import FileChooser\n",
    "from ipywidgets import TwoByTwoLayout\n",
    "from ipywidgets import GridspecLayout\n",
    "\n",
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import time\n",
    "import math\n",
    "from scipy.signal import savgol_filter\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import smtplib \n",
    "from email.mime.multipart import MIMEMultipart \n",
    "from email.mime.text import MIMEText \n",
    "from email.mime.base import MIMEBase \n",
    "from email import encoders  \n",
    "# Set it to None to display all columns in the dataframe\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 5000)\n",
    "pd.options.mode.chained_assignment = None \n",
    "plt.rc('figure', max_open_warning = 0)\n",
    "\n",
    "\n",
    "IFrame(src='https://rikvalentini.wixsite.com/naturetalkers', width=1000, height=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INPUT YOUR TT CLOUD NUMBER AND OPERATION MODE\n",
    "> loop ON mode if you want to automatic updates every hour your data files, otherwise for single run do not check the box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cloudID=widgets.Text('Input TTCLoud serial number')\n",
    "display (cloudID)\n",
    "\n",
    "loop_on=widgets.Checkbox(\n",
    "    value=False,\n",
    "    description='Loop ON',\n",
    "    disabled=False,\n",
    "    indent=False\n",
    ")\n",
    "\n",
    "display (loop_on)\n",
    "time_cycle=widgets.Text('time cycle in seconds')\n",
    "display (time_cycle)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INPUT YOUR DATA FOLDER PATH\n",
    "##### obligatory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# selecting names directory --- the same folder will contain the elaborated files\n",
    "fc = FileChooser('/Users/')\n",
    "display(fc)\n",
    "# fc.selected  is file path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input the Email addresses to send TTs battery report \n",
    "###### insert email addresses separated by commas (i.e. rik@unitus.it, rikvalentini@gmail.com,....)\n",
    "> uncheck box if you do not want send emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mail messaging handling\n",
    "\n",
    "if os.path.isfile(fc.selected_path+'/mail_params.csv') :\n",
    "\n",
    "    \n",
    "    with open (fc.selected_path+'/'+'mail_params.csv','r') as f:\n",
    "            reader = csv.reader(f, delimiter=',')\n",
    "            data_mail = next(reader)\n",
    "    \n",
    "\n",
    "    \n",
    "            \n",
    "else:\n",
    "    \n",
    "    data_mail[0]=''\n",
    "    data_mail[1]=''\n",
    "    data_mail[2]=''\n",
    "    data_mail[3]=''\n",
    "    data_mail[4]=''\n",
    "\n",
    "mail_addr_from=widgets.Text(description='FROM',value=data_mail[0])\n",
    "mail_addr_to=widgets.Text(description='TO',value=data_mail[1])\n",
    "mail_smtp=widgets.Text(description='SMTP server',value=data_mail[2])\n",
    "mail_port=widgets.Text(description='SMTP port',value=data_mail[3])\n",
    "mail_pw=widgets.Text(description='Password',value=data_mail[4])\n",
    "display (mail_addr_from)\n",
    "display (mail_addr_to)\n",
    "display (mail_smtp)\n",
    "display (mail_port)\n",
    "display (mail_pw)\n",
    "\n",
    "mail_on=widgets.Checkbox(\n",
    "    value=False,\n",
    "    description='Send mail',\n",
    "    disabled=False,\n",
    "    indent=False\n",
    ")\n",
    "\n",
    "mail_store=widgets.Checkbox(\n",
    "    value=False,\n",
    "    description='Store mail addr',\n",
    "    disabled=False,\n",
    "    indent=False\n",
    ")\n",
    "\n",
    "\n",
    "display (mail_on)\n",
    "display (mail_store)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RUN THE CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#Data transformation in physical units\n",
    "def transf():\n",
    "    dfn['Tref_0c']=127.6-0.006045*dfn['Tref_0'] + 1.26E-07*dfn['Tref_0']**2 -1.15E-12*dfn['Tref_0']**3\n",
    "    dfn['Tref_1c']=127.6-0.006045*dfn['Tref_1'] + 1.26E-07*dfn['Tref_1']**2 -1.15E-12*dfn['Tref_1']**3\n",
    "    dfn['Theat_0c']=127.6-0.006045*dfn['Theat_0'] + 1.26E-07*dfn['Theat_0']**2 -1.15E-12*dfn['Theat_0']**3\n",
    "    dfn['Theat_1c']=127.6-0.006045*dfn['Theat_1'] + 1.26E-07*dfn['Theat_1']**2 -1.15E-12*dfn['Theat_1']**3\n",
    "    #dfn['growth_sensor_c']=194.856731-0.008274771*dfn.growth_sensor+1.63685E-07*dfn.growth_sensor**2-1.58251E-12*dfn.growth_sensor**3+ 5.96455E-18*dfn.growth_sensor**4\n",
    "    dfn['growth_sensor_c']=-0.0006*dfn['growth_sensor']+61.079\n",
    "    dfn['angle_mean_c']=np.arctan((dfn['g_xmean']**2+(dfn['g_ymean']**2)/dfn['g_zmean'])**0.5)*90/(np.pi/2)\n",
    "    dfn['trunk_axis_movement']=dfn['g_xstd']+dfn['g_ystd']+dfn['g_zstd']\n",
    "    dfn['Vbat_c']= round(2*1100*dfn['adc_Vbat']/dfn['adc_bandgap']/1000,2)\n",
    "    dfn['date'] = pd.to_datetime(dfn['timestamp'],unit='s').dt.tz_localize('UTC').dt.tz_convert('CET').dt.tz_localize(None)\n",
    "    dfn['day']=dfn['date'].dt.strftime('%j').astype(float)\n",
    "    dfn['hour']=dfn['date'].dt.strftime('%H').astype (float)\n",
    "    dfn['doy']=dfn['day']+ dfn['hour']/24\n",
    "    #dfn['date'].dt.tz_localize('utc').dt.tz_convert('Europe/Rome') in case of usimng EU time\n",
    "    dfn['datetime'] = dfn['date'].dt.strftime('%d/%m/%Y/%H:%M:%S')\n",
    "    \n",
    "    dfn['air_temperature'] = dfn['air_temperature']/10\n",
    "\n",
    "def time_check ():\n",
    "    for j in range (0,len(dfn)-1):\n",
    "        if dfn.loc[j,'timestamp'] < 1.59E9:\n",
    "            dfn.drop ([j],axis=0,inplace =True)\n",
    "    dfn.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "def sav_gol_filter ():    \n",
    "    #x = dfn['timestamp']\n",
    "    dfn['Tref_0f'] = savgol_filter(dfn['Tref_0c'], 11, 2,mode='nearest') # window size 5, polynomial order 3\n",
    "    dfn['Tref_1f'] = savgol_filter(dfn['Tref_1c'], 11, 2,mode='nearest') # window size 5, polynomial order 3\n",
    "    dfn['Theat_0f'] = savgol_filter(dfn['Theat_0c'], 11, 2,mode='nearest') # window size 5, polynomial order 3\n",
    "    dfn['Theat_1f'] = savgol_filter(dfn['Theat_1c'], 11, 2,mode='nearest') # window size 5, polynomial order 3\n",
    "       \n",
    "\n",
    "def elab_sapflow():\n",
    "    \n",
    "    #filtering temperature data using Savitzkyâ€“Golay filter\n",
    "    \n",
    "    \n",
    "    #do equation   \n",
    "    \n",
    "    dfn['dTon']= dfn['Theat_1f']-dfn['Tref_1f']\n",
    "    dfn['dToff']=dfn['Theat_0f']-dfn['Tref_0f']\n",
    "    dfn['dTindex']=dfn['dTon']-dfn['dToff']\n",
    "    \n",
    "    #dfn['dTindex']=dfn['Theat_1f']-dfn['Tref_1f'] #just for granier\n",
    "    dTmax= dfn.groupby(['day'])[\"dTindex\"].max()\n",
    "    \n",
    "\n",
    "    for j in range (0,len(dfn)):\n",
    "        try:\n",
    "            dTmax_value = dTmax[dfn.loc[j,'day']]\n",
    "        except:\n",
    "            continue\n",
    "         #to stabilize DTmax in night\n",
    "        #if dfn.loc[j,'a_610']<10:\n",
    "            #dfn.loc[j,'dTindex']=dTmax_value\n",
    "        \n",
    "        dfn.loc[j,'sap_flow_density_raw']=12.95*((dTmax_value/dfn.loc[j,'dTindex'])-1)*27.77 #transf from l dm-2 h-1 to g m-2 s-1\n",
    "    \n",
    "    \n",
    "    \n",
    "    dfn['sap_flow_density']=dfn.loc[0:len(dfn),'sap_flow_density_raw'].rolling(window=4).mean() # rolling mean of interpolated data\n",
    "    \n",
    "    # granier equation\n",
    "    #dfn['dTindex']=dfn['Theat_1c']-dfn['Tref_1c']\n",
    "    #for j in range (25,len(dfn)):\n",
    "        #dTmax=dfn.loc[j-25:j,'dTindex'].max()\n",
    "        #dfn.loc[j,'sap_flow_density']=118.99*10000*((dTmax/(dfn.loc[j,'dTindex'])-1))/3600 #transf from g m-2 s-1 to g cm-2 h-1\n",
    "        \n",
    "       \n",
    "def elab_growth():\n",
    "    \n",
    "    dfn_night=dfn[dfn['a_650']==0]# select only night values\n",
    "    dfn['growth_sensor_night']=dfn_night['growth_sensor_c']\n",
    "    avg_g=dfn['growth_sensor_night'].median()# calculate median\n",
    "    std_g=dfn['growth_sensor_night'].std()#calculate std\n",
    "    \n",
    "    for j in range (0,len(dfn)):\n",
    "            if dfn.loc[j,'growth_sensor_night']>avg_g+2*std_g or dfn.loc[j,'growth_sensor_night']<avg_g-2*std_g: # correct for numbers outside +- 2*std\n",
    "                dfn.loc[j,'growth_sensor_night']=avg_g #replace outliers with median \n",
    "    dfn.growth_sensor_night.interpolate(method='pad',axis=0, inplace=True) #interpolation of missing data NaN\n",
    "    dfn['growth_roll']=dfn.loc[0:len(dfn),'growth_sensor_night'].rolling(window=200).mean() # rolling mean of interpolated data\n",
    "    dfn['growth_roll_diff']=dfn['growth_roll'].diff() # derivative (growth) of the distance\n",
    "    dfn.loc[dfn.growth_roll_diff>0,'growth_roll_diff']=0  #to be applied in case we want non-negative growth\n",
    "    \n",
    "    dfn['radial_growth']=-dfn['growth_roll_diff'].cumsum() # cumulative growth (negative since growth equal less distance from trunk)\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "def elab_stem_humidity():\n",
    "    #dfn['stem_humidity']=((dfn.freq-(-74.149*dfn['Tref_0c']) + 33165)*-0.0001+1.9581)*100 # according to shahla\n",
    "    a=-72.768*dfn['Tref_0f'] + 27392 # probe in water sensitivity\n",
    "    dfn['stem_humidity']=((1-(dfn.freq-a)/a))*100 # this is as reference to water 100%\n",
    "      \n",
    "\n",
    "def elab_light ():\n",
    "   \n",
    "\n",
    "    dfn.loc[dfn.a_610 >65532,'a_610']=np.nan\n",
    "    dfn.loc[dfn.a_680 >65532,'a_680']=np.nan\n",
    "    dfn.loc[dfn.a_730 >65532,'a_730']=np.nan\n",
    "    dfn.loc[dfn.a_760 >65532,'a_760']=np.nan\n",
    "    dfn.loc[dfn.a_810 >65532,'a_810']=np.nan\n",
    "    dfn.loc[dfn.a_860 >65532,'a_860']=np.nan\n",
    "    dfn.loc[dfn.a_450 >65532,'a_450']=np.nan\n",
    "    dfn.loc[dfn.a_500 >65532,'a_500']=np.nan\n",
    "    dfn.loc[dfn.a_550 >65532,'a_550']=np.nan\n",
    "    dfn.loc[dfn.a_570 >65532,'a_570']=np.nan\n",
    "    dfn.loc[dfn.a_600 >65532,'a_600']=np.nan\n",
    "    dfn.loc[dfn.a_650 >65532,'a_650']=np.nan\n",
    "    \n",
    "    dfn['ndvi_raw']=(dfn.a_760-dfn.a_680)/(dfn.a_760+dfn.a_680)\n",
    "    dfn.ndvi_raw.interpolate(method='pad',axis=0, inplace=True) #interpolation of missing data NaN\n",
    "    dfn.loc[dfn.ndvi_raw <0,'ndvi_raw']=0\n",
    "    dfn['ndvi']=dfn.loc[0:len(dfn),'ndvi_raw'].rolling(window=4).mean() # rolling mean of interpolated data\n",
    "    \n",
    "    dfn['green_red_raw']=(dfn.a_570-dfn.a_680)/(dfn.a_570+dfn.a_680)\n",
    "    dfn.green_red_raw.interpolate(method='pad',axis=0, inplace=True) #interpolation of missing data NaN\n",
    "    dfn.loc[dfn.green_red_raw <0,'green_red_raw']=0\n",
    "    dfn['green_red']=dfn.loc[0:len(dfn),'green_red_raw'].rolling(window=4).mean() # rolling mean of interpolated data\n",
    "\n",
    "    \n",
    "#Showing batteries voltage\n",
    "def Vbat_show():\n",
    "    print (names_tt[i],dfn.loc[len(dfn)-1,'Vbat_c'],dfn.loc[len(dfn)-1,'date'])\n",
    "    #dt.datetime.fromtimestamp(1596725594).strftime('%Y-%m-%d %H:%M:%S %j' )\n",
    "\n",
    "    \n",
    "#Sending report check\n",
    "def Vbat_mail():\n",
    "    \n",
    "    toaddr = data_mail[1].split(',') # this create a list of mail addresses\n",
    "    fromaddr = data_mail[0]\n",
    "    smtp=data_mail[2]\n",
    "    port=data_mail[3]\n",
    "    pw=data_mail[4]\n",
    "    \n",
    "    \n",
    "     # instance of MIMEMultipart \n",
    "    msg = MIMEMultipart() \n",
    "      \n",
    "    # storing the senders email address   \n",
    "    msg['From'] = fromaddr \n",
    "      \n",
    "    # storing the receivers email address  \n",
    "  \n",
    "    msg['To'] = ', '.join(toaddr)\n",
    "    # storing the subject  \n",
    "    msg['Subject'] = cloudID_tt\n",
    "      \n",
    "    # string to store the body of the mail \n",
    "    body = \"Battery test\"\n",
    "      \n",
    "    # attach the body with the msg instance \n",
    "    msg.attach(MIMEText(body, 'plain')) \n",
    "      \n",
    "    # open the file to be sent  \n",
    "    filename = url_proj+'/'+cloudID_tt+'_BAT_'+day+'.csv'\n",
    "    attachment = open(filename, \"rb\") \n",
    "      \n",
    "    # instance of MIMEBase and named as p \n",
    "    p = MIMEBase('application', 'octet-stream') \n",
    "      \n",
    "    # To change the payload into encoded form \n",
    "    p.set_payload((attachment).read()) \n",
    "      \n",
    "    # encode into base64 \n",
    "    encoders.encode_base64(p) \n",
    "       \n",
    "    p.add_header('Content-Disposition', \"attachment; filename= %s\" % cloudID_tt+'_BAT_'+day+'.csv') \n",
    "      \n",
    "    # attach the instance 'p' to instance 'msg' \n",
    "    msg.attach(p) \n",
    "      \n",
    "    # creates SMTP session \n",
    "    s = smtplib.SMTP_SSL(smtp, port) \n",
    "      \n",
    "    # start TLS for security \n",
    "    #s.starttls() \n",
    "      \n",
    "    # Authentication \n",
    "    s.login(fromaddr, pw) \n",
    "      \n",
    "    # Converts the Multipart msg into a string \n",
    "    text = msg.as_string() \n",
    "      \n",
    "    # sending the mail \n",
    "    s.sendmail(fromaddr, toaddr, text) \n",
    "      \n",
    "    # terminating the session \n",
    "    s.quit() \n",
    "\n",
    "#----------------MAIN programme start--------------------\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "url_proj= fc.selected_path\n",
    "\n",
    "    # Store mail parameters\n",
    "\n",
    "if mail_store.value:\n",
    "    \n",
    "    with open (url_proj+'/'+'mail_params.csv','w') as f:\n",
    "               \n",
    "                data_writer = csv.writer(f, delimiter=',')\n",
    "                data_writer.writerow(data_mail)\n",
    "\n",
    "\n",
    "    #READ THE CLOUD    \n",
    "\n",
    "flag_bat=1\n",
    "cloudID_tt=cloudID.value\n",
    "\n",
    "\n",
    "#TTcloud_tt=url_site+cloudID_tt\n",
    "\n",
    "cols=['timestamp','tree_talker', 'sap_flow_density','stem_humidity','radial_growth','ndvi','green_red','air_temperature','rel_air_humidity','trunk_axis_movement']\n",
    "\n",
    "#dfn_cum=pd.DataFrame(columns=cols) \n",
    "dfn_day=pd.DataFrame(columns=cols) \n",
    "\n",
    "d=dt.datetime.now()\n",
    "old_day=d.strftime('%d.%m.%Y')\n",
    "        \n",
    "        \n",
    "while True:\n",
    "  \n",
    "        \n",
    "        t0=time.time()\n",
    "        ts = str(int(time.time()))\n",
    "       \n",
    "       \n",
    "        \n",
    "        \n",
    "        while True :\n",
    "            try:\n",
    "                    print (\"job start at ... \",dt.datetime.now())\n",
    "                    url_tt = 'http://naturetalkers.altervista.org/'+cloudID_tt+'/ttcloud.txt'\n",
    "                    df_tt=pd.read_csv(url_tt, sep=',',engine='python',header=None)\n",
    "                    \n",
    "            except:\n",
    "                    print (\"altervista server failure .....\")\n",
    "                    time.sleep(6)\n",
    "                    pass\n",
    "            else:\n",
    "                    break\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "       \n",
    "        \n",
    "        # search for TTs names\n",
    "        names_tt=[]\n",
    "        for j in range (len(df_tt)-1):\n",
    "                if  df_tt.loc[j+1,1].split(';')[0] !=  df_tt.loc[j,1].split(';')[0]:\n",
    "                    names_tt.append(df_tt.loc[j,1].split(';')[0])\n",
    "        names_tt = list(dict.fromkeys(names_tt))\n",
    "        names_tt.remove(cloudID_tt)  \n",
    "        \n",
    "        #dtt=pd.read_csv(fc.selected, sep=',',index_col=False, engine='python',header=0)\n",
    "        #dtt.ID=dtt.ID.astype(str)\n",
    "      \n",
    "     \n",
    "        print ('Data retrieval time seconds .....',time.time()-t0)\n",
    "        print ('waiting elaboration.....')\n",
    "        t1=time.time()\n",
    "               \n",
    "        #CREATE DATAFRAME FOR TT AND TT FIRE\n",
    "        \n",
    "        a=[]\n",
    "        col0=df_tt.iloc[:,0].to_list()\n",
    "        col1=df_tt.iloc[:,1].to_list() \n",
    "        for i in range (len(col1)):\n",
    "                a.append(col1[i].split(';'))\n",
    "        dfraw=pd.DataFrame(a)\n",
    "        df_tt=dfraw\n",
    "        #df_tt=dfraw[480*31:len(dfraw)] # we take data after 240 hours of stabilizatio (10 days)\n",
    "        df_tt.reset_index(drop=True,inplace=True)\n",
    "        \n",
    "               \n",
    "               \n",
    "        \n",
    "        #TREE TALKER SECTION\n",
    "        \n",
    "        #CLEANING DATAFRAME GENERATING COMBINED STRING 49 AND 4D FOR ID of treetalkers\n",
    "        \n",
    "      \n",
    "        \n",
    "        \n",
    "        \n",
    "        #dfn_cum.to_csv (url_names+'_'+day+'.csv',index=False)\n",
    "        df_Vbat=pd.DataFrame(columns=['ID','date','Vbat'])\n",
    "\n",
    "\n",
    "        for i in range (0,len(names_tt)):\n",
    "                dfn_day=pd.DataFrame(columns=cols)\n",
    "                dfx=df_tt[df_tt.iloc[:,0]==names_tt[i]]\n",
    "                if len(dfx)==0:\n",
    "                    print (names_tt[i], 'missing')\n",
    "                    row_bat=[names_tt[i],old_day,'missing']                 \n",
    "                    df_Vbat.loc[len(df_Vbat)]=row_bat\n",
    "                    continue\n",
    "            \n",
    "                dfn1=dfx[dfx.iloc[:,2]=='4D']\n",
    "                col_delete=[1,2,21,22,23,24,25,26,27,28,29] \n",
    "                dfn1.drop(col_delete,axis=1,inplace =True)\n",
    "                col1=['tree_talker','timestamp','Tref_0','Theat_0','growth_sensor',\n",
    "                'adc_bandgap','bits','rel_air_humidity','air_temperature','g_zmean','g_zstd','g_ymean','g_ystd','g_xmean','g_xstd','Tref_1','Theat_1','freq','adc_Vbat']\n",
    "                dfn1.columns=col1\n",
    "                dfn1.drop_duplicates(subset=None, inplace=True)\n",
    "                dfn1.reset_index(drop=True, inplace=True)\n",
    "                \n",
    "                dfn2=dfx[dfx.iloc[:,2]=='49']\n",
    "                col_delete=[1,2,18,19,20,21,22,23,24,25,26,27,28,29] \n",
    "                dfn2.drop(col_delete,axis=1,inplace =True)\n",
    "                col2=['tree_talker','timestamp','a_610','a_680','a_730','a_760','a_810','a_860','a_450','a_500','a_550','a_570','a_600','a_650','integration_time','gain']\n",
    "                dfn2.columns=col2\n",
    "                dfn2.drop_duplicates(subset=None, inplace=True)\n",
    "                dfn2.reset_index(drop=True, inplace=True)\n",
    "                \n",
    "                dfn=pd.merge(dfn1,dfn2,on=['tree_talker','timestamp'])\n",
    "                dfn.drop_duplicates(subset=None, inplace=True)\n",
    "                dfn.reset_index(drop=True, inplace=True)\n",
    "                \n",
    "                dfn.timestamp=dfn.timestamp.astype(int)\n",
    "                dfn.timestamp=round(dfn.timestamp/10)*10\n",
    "                for j in dfn.columns[2:32]:\n",
    "                    dfn[j]=dfn[j].astype(float)\n",
    "               \n",
    "                dfn['timestamp']=dfn['timestamp'].astype(int)\n",
    "                time_check()\n",
    "                dfn.to_csv(url_proj+'/'+names_tt[i]+'_raw.csv',index=False)\n",
    "                transf()\n",
    "                dfn.to_csv(url_proj+'/'+names_tt[i]+'_transf.csv',index=False)\n",
    "                \n",
    "               \n",
    "                #Vbat_show()\n",
    "               \n",
    "                sav_gol_filter ()\n",
    "                elab_sapflow()\n",
    "                elab_growth()\n",
    "                elab_stem_humidity()\n",
    "                elab_light()\n",
    "                \n",
    "                row_bat=[dfn.loc[len(dfn)-1,'tree_talker'],dfn.loc[len(dfn)-1,'datetime'],dfn.loc[len(dfn)-1,'Vbat_c']]          \n",
    "                df_Vbat.loc[len(df_Vbat)]=row_bat\n",
    "               \n",
    "                dfn.to_csv(url_proj+'/'+names_tt[i]+'_elab.csv',index=False)\n",
    "                \n",
    "                dfn_c=dfn[['tree_talker', 'timestamp','date','sap_flow_density','stem_humidity','radial_growth','ndvi','green_red','air_temperature','rel_air_humidity','trunk_axis_movement']]\n",
    "                dfn_c.reset_index(drop=True, inplace=True)\n",
    "                \n",
    "             \n",
    "                d=dt.datetime.now()\n",
    "                day=d.strftime('%d.%m.%Y')\n",
    "                last_date = pd.to_datetime(dfn_c.loc[len(dfn_c)-1,'timestamp'],unit='s')\n",
    "    \n",
    "                last_date=last_date.strftime('%d/%m/%Y/%H:%M:%S')\n",
    "                #dfn_c['date']=last_date\n",
    "                #dfn_cum.loc[len(dfn_cum)]=dfn_tot.loc[len(dfn_tot)-1]\n",
    "                \n",
    "               \n",
    "                dfn_day.loc[len(dfn_day)]=dfn_c.loc[len(dfn_c)-1]\n",
    "                \n",
    "                file_day =url_proj+'/'+cloudID_tt+'_'+day\n",
    "                if os.path.exists(file_day+'.csv'):\n",
    "                    bol=False\n",
    "                else:\n",
    "                    bol=True\n",
    "                with open(file_day+'.csv','a+') as f:\n",
    "                           dfn_day.to_csv(f,index=False,header=bol)\n",
    "                \n",
    "              \n",
    "                \n",
    "        \n",
    "        \n",
    "              \n",
    "      \n",
    "        df_Vbat.to_csv(url_proj+'/'+cloudID_tt+'_BAT_'+day+'.csv',index=False)\n",
    "        \n",
    "        if (day != old_day or flag_bat==1) and mail_on.value:# flag 1 only when you start script for the first time\n",
    "            Vbat_mail()\n",
    "            old_day=day\n",
    "            flag_bat=0\n",
    "       \n",
    "        \n",
    "       \n",
    "        print ('TT total elaboration time seconds .....',time.time()-t1)\n",
    "        display (df_Vbat)\n",
    "        \n",
    "        \n",
    "       \n",
    "        if loop_on.value:\n",
    "            time.sleep(time_cycle.value)\n",
    "        else:\n",
    "            print ('job ended')\n",
    "            break\n",
    "            \n",
    "        print('Waiting next job .......')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SELECT single TT\n",
    "##### select variables (doy= julian date and it is fixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TT_name=widgets.Dropdown(\n",
    "    options=names_tt,\n",
    "    value=names_tt[0],\n",
    "    description='Select TT:',\n",
    "    disabled=False,\n",
    ")\n",
    "\n",
    "variable_name_x=widgets.Dropdown(\n",
    "    options=dfn.columns,\n",
    "    value=dfn.columns[44],\n",
    "    description='X:',\n",
    "    disabled=True,\n",
    ")\n",
    "variable_name_y=widgets.Dropdown(\n",
    "    options=dfn.columns,\n",
    "    value=dfn.columns[54],\n",
    "    description='Y:',\n",
    "    disabled=False,\n",
    ")\n",
    "\n",
    "\n",
    "#display (TT_name)\n",
    "\n",
    "TwoByTwoLayout(top_left=TT_name,\n",
    "               bottom_left=variable_name_x,\n",
    "               bottom_right=variable_name_y,\n",
    "               merge=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RUN the single graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dfn=pd.read_csv(url_proj+'/'+TT_name.value+'_elab.csv', sep=',',engine='python',header=0)\n",
    "\n",
    "def f(xmin,xmax,ymin,ymax):\n",
    "    \n",
    "    \n",
    "    plt.figure(figsize=(15,4))\n",
    "    plt.title(TT_name.value)\n",
    "\n",
    "        ##plt.ylim(61000,70000)\n",
    "    #plt.plot(dfn['doy'],dfn['dTindex'],color='y')\n",
    "    plt.plot(dfn[variable_name_x.value],dfn[variable_name_y.value],color='r')\n",
    "    #plt.plot(dfn[variable_name_x.value],dfn['Tref_0f'],color='b')\n",
    "    \n",
    "    #plt.plot(dfn['doy'],dfn[variable_name_y.value],color='b')\n",
    "    #plt.plot(dfn['doy'],dfn['dTindex'],color='b')\n",
    "\n",
    "#y_filt = savgol_filter(dfn['Tref_0c'], 5, 3) # window size 51, polynomial order 3\n",
    "#matplotlib.pyplot\n",
    "#plt.plot_date(dates, values)\n",
    "\n",
    "#plt.plot(x,y)\n",
    "    plt.xlim(xmin,xmax)\n",
    "    plt.ylim(ymin,ymax)\n",
    "    return \n",
    "\n",
    "xmin = widgets.IntSlider(description='xmin:',min=0,max=365,value=200)\n",
    "xmax = widgets.IntSlider(description='xmax:',min=0,max=365,value=300)\n",
    "ymin = widgets.IntSlider(description='ymin:',min=0,max=100,value=0)\n",
    "ymax = widgets.IntSlider(description='ymax:',min=0,max=300,value=30)\n",
    "\n",
    "ui = widgets.HBox([xmin, xmax,ymin,ymax])\n",
    "out = widgets.interactive_output(f, {'xmin': xmin,'xmax':xmax,'ymin': ymin,'ymax':ymax})\n",
    "display(ui, out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select all TTs and  set graphs\n",
    "##### select y variable and x, y ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridspecLayout(3, 2)\n",
    "\n",
    "variable_name_x=widgets.Dropdown(\n",
    "    options=dfn.columns,\n",
    "    value=dfn.columns[44],\n",
    "    description='X:',\n",
    "    disabled=True,\n",
    ")\n",
    "variable_name_y=widgets.Dropdown(\n",
    "    options=dfn.columns,\n",
    "    value=dfn.columns[54],\n",
    "    description='Y:',\n",
    "    disabled=False,\n",
    ")\n",
    "\n",
    "xmin = widgets.IntSlider(description='xmin:',min=0,max=365,value=200)\n",
    "xmax = widgets.IntSlider(description='xmax:',min=0,max=365,value=300)\n",
    "ymin = widgets.IntSlider(description='ymin:',min=0,max=100,value=0)\n",
    "ymax = widgets.IntSlider(description='ymax:',min=0,max=300,value=30)\n",
    "\n",
    "grid[0,0]=variable_name_x\n",
    "grid[0,1]=variable_name_y\n",
    "grid[1,0]=xmin\n",
    "grid[1,1]=xmax\n",
    "grid[2,0]=ymin\n",
    "grid[2,1]=ymax\n",
    "\n",
    "\n",
    "\n",
    "#display (TT_name)\n",
    "grid\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RUN all graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "for i in names_tt:\n",
    "    \n",
    "    dfn=pd.read_csv(url_proj+'/'+i+'_elab.csv', sep=',',engine='python',header=0)\n",
    "    \n",
    "    \n",
    "    plt.figure(figsize=(15,4))\n",
    "    plt.title(i+\"-\"+variable_name_y.value)\n",
    "    plt.plot(dfn[variable_name_x.value],dfn[variable_name_y.value],color='r')\n",
    "    \n",
    "    plt.xlim(xmin.value,xmax.value)\n",
    "    plt.ylim(ymin.value,ymax.value)\n",
    "    \n",
    "          \n",
    "           \n",
    "\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
