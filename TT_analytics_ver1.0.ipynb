{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TT data analytics by RV ver1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1000\"\n",
       "            height=\"1000\"\n",
       "            src=\"https://rikvalentini.wixsite.com/naturetalkers\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fba2b798d00>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from IPython.display import Javascript\n",
    "#Javascript(\"Jupyter.notebook.execute_cells([2,3])\")\n",
    "from IPython.display import IFrame\n",
    "\n",
    "IFrame(src='https://rikvalentini.wixsite.com/naturetalkers', width=1000, height=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INPUT YOUR TT CLOUD NUMBER AND OPERATION MODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2a0092b20ea46a597d1348e34b8f5a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='Input TTCLoud serial number')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcec4ef59e534e8dae5bcda9bd96313d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Checkbox(value=False, description='Loop ON', indent=False)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import FileUpload\n",
    "from IPython.display import Javascript\n",
    "\n",
    "TT_cloud=widgets.Text('Input TTCLoud serial number')\n",
    "display (TT_cloud)\n",
    "\n",
    "loop_on=widgets.Checkbox(\n",
    "    value=False,\n",
    "    description='Loop ON',\n",
    "    disabled=False,\n",
    "    indent=False\n",
    ")\n",
    "\n",
    "display (loop_on)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INPUT YOUR TTs SERIAL NUMBERS\n",
    ">You can prepare an excel file with one column containing the TTs serial numbers \n",
    ">with the column name 'ID' and save as .csv file (see example)\n",
    "\n",
    "\n",
    "\n",
    "|  ID  |\n",
    "|-|\n",
    "|   52060652  |\n",
    "|   52060669  |\n",
    "|   52060671  |\n",
    "|   52060656  |\n",
    "|   52060668  |\n",
    "|   52060664  |\n",
    "|   52060667  |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4265c379fa2947bcad7cce5b0418fcad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileChooser(path='/Users', filename='', title='HTML(value='', layout=Layout(display='none'))', show_hidden='Fa…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ipyfilechooser import FileChooser\n",
    "fc = FileChooser('/Users/')\n",
    "display(fc)\n",
    "# fc.selected  is file path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input the Email addresses to send TTs battery report (skip it if you do not need this function)\n",
    "###### insert email addresses separated by commas (i.e. rik@unitus.it, rikvalentini@gmail.com,....)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mail_addr=widgets.Text('i.e. rik@unitus.it,...')\n",
    "display (mail_addr)\n",
    "# mail_list = mail_addr.value.split(',') # this create a list of mail addresses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "button = widgets.Button(description=\"Run code\")\n",
    "output = widgets.Output()\n",
    "display(button, output)\n",
    "def on_button_clicked(button):\n",
    "       with output:\n",
    "        display(Javascript('IPython.notebook.execute_cells_below()'))\n",
    "button.on_click(on_button_clicked)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fc.selected)# this is file path\n",
    "print (mail_addr.value) \n",
    "mail_list = mail_addr.value.split(',') # this create a list of mail addresses\n",
    "print (mail_list)\n",
    "print (loop_on.value)  #True if box checked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import time\n",
    "import math\n",
    "from ftplib import FTP\n",
    "import csv\n",
    "import dask.dataframe as dd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import smtplib \n",
    "from email.mime.multipart import MIMEMultipart \n",
    "from email.mime.text import MIMEText \n",
    "from email.mime.base import MIMEBase \n",
    "from email import encoders  \n",
    "# Set it to None to display all columns in the dataframe\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 5000)\n",
    "pd.options.mode.chained_assignment = None \n",
    "\n",
    "\n",
    "\n",
    "#Data transformation in physical units\n",
    "def transf():\n",
    "    dfn['Tref_0c']=127.6-0.006045*dfn['Tref_0'] + 1.26E-07*dfn['Tref_0']**2 -1.15E-12*dfn['Tref_0']**3\n",
    "    dfn['Tref_1c']=127.6-0.006045*dfn['Tref_1'] + 1.26E-07*dfn['Tref_1']**2 -1.15E-12*dfn['Tref_1']**3\n",
    "    dfn['Theat_0c']=127.6-0.006045*dfn['Theat_0'] + 1.26E-07*dfn['Theat_0']**2 -1.15E-12*dfn['Theat_0']**3\n",
    "    dfn['Theat_1c']=127.6-0.006045*dfn['Theat_1'] + 1.26E-07*dfn['Theat_1']**2 -1.15E-12*dfn['Theat_1']**3\n",
    "    #dfn['growth_sensor_c']=194.856731-0.008274771*dfn.growth_sensor+1.63685E-07*dfn.growth_sensor**2-1.58251E-12*dfn.growth_sensor**3+ 5.96455E-18*dfn.growth_sensor**4\n",
    "    dfn['growth_sensor_c']=-0.0006*dfn['growth_sensor']+61.079\n",
    "    dfn['angle_mean_c']=np.arctan((dfn['g_xmean']**2+(dfn['g_ymean']**2)/dfn['g_zmean'])**0.5)*90/(np.pi/2)\n",
    "    dfn['trunk_axis_movement']=dfn['g_xstd']+dfn['g_ystd']+dfn['g_zstd']\n",
    "    dfn['Vbat_c']= round(2*1100*dfn['adc_Vbat']/dfn['adc_bandgap']/1000,2)\n",
    "    dfn['date'] = pd.to_datetime(dfn['timestamp'],unit='s')\n",
    "    #dfn['date'].dt.tz_localize('utc').dt.tz_convert('Europe/Rome') in case of usimng EU time\n",
    "    dfn['date'] = dfn['date'].dt.strftime('%d/%m/%Y/%H:%M:%S')\n",
    "    dfn['air_temperature'] = dfn['air_temperature']/10\n",
    "\n",
    "def transf_ff():\n",
    "    dfn1['air_temperature_ff'] = dfn1['air_temperature_ff']/10\n",
    "    dfn1['gas_co2']=dfn1['gas_co2']*1.25-500. # see MHZ19B datasheet 0-2000 ppm --> 400 - 2000 mVolts\n",
    "    dfn1['gas_o3']=dfn1['gas_o3']*-0.076+390 # see mq131 (low concebration manual) 10 - 200 ppb  ---> 5000 - 2500 mVolts\n",
    "    dfn1['gas_o3']=dfn1['gas_o3']*48/24.45 # conversion in ug m-3\n",
    "    #dfn1['leaf_temperature']=dfn1['leaf_temperature']/210 -273.15 # conversione 210 counts/K\n",
    "    dfn1['leaf_temperature']=25+(dfn1['leaf_temperature']-64500)/210  # conversione 210 counts/K con offset di 64500@25°C see excelitas data sheet TPS 1S 1051\n",
    "    dfn1['air_temperature_IR']=25+ (dfn1['air_temperature_IR']-8200)/90  # conversione 90 counts/K con offset di 8200@25°C\n",
    "    dfn1['date'] = pd.to_datetime(dfn1['timestamp'],unit='s')\n",
    "    #dfn['date'].dt.tz_localize('utc').dt.tz_convert('Europe/Rome') in case of usimng EU time\n",
    "    \n",
    "    \n",
    "\n",
    "#Showing batteries voltage\n",
    "def Vbat_show():\n",
    "    print (names_tt[i],dfn.loc[len(dfn)-1,'Vbat_c'],dfn.loc[len(dfn)-1,'date'])\n",
    "    #dt.datetime.fromtimestamp(1596725594).strftime('%Y-%m-%d %H:%M:%S %j' )\n",
    "\n",
    "#Sending report check\n",
    "def Vbat_mail():\n",
    "\n",
    "    fromaddr = \"rikvalentini@libero.it\"\n",
    "    toaddr = [\"rik@unitus.it\",\"micaela@nature4.org\",\"filippopiacente@gmail.com\"]\n",
    "    \n",
    "    # instance of MIMEMultipart \n",
    "    msg = MIMEMultipart() \n",
    "      \n",
    "    # storing the senders email address   \n",
    "    msg['From'] = fromaddr \n",
    "      \n",
    "    # storing the receivers email address  \n",
    "  \n",
    "    msg['To'] = ', '.join(toaddr)\n",
    "    # storing the subject  \n",
    "    msg['Subject'] = url_site\n",
    "      \n",
    "    # string to store the body of the mail \n",
    "    body = \"Battery test\"\n",
    "      \n",
    "    # attach the body with the msg instance \n",
    "    msg.attach(MIMEText(body, 'plain')) \n",
    "      \n",
    "    # open the file to be sent  \n",
    "    filename = url_proj+'/'+url_site+'/'+url_site+'_BAT_'+day+'.csv'\n",
    "    attachment = open(filename, \"rb\") \n",
    "      \n",
    "    # instance of MIMEBase and named as p \n",
    "    p = MIMEBase('application', 'octet-stream') \n",
    "      \n",
    "    # To change the payload into encoded form \n",
    "    p.set_payload((attachment).read()) \n",
    "      \n",
    "    # encode into base64 \n",
    "    encoders.encode_base64(p) \n",
    "       \n",
    "    p.add_header('Content-Disposition', \"attachment; filename= %s\" % filename) \n",
    "      \n",
    "    # attach the instance 'p' to instance 'msg' \n",
    "    msg.attach(p) \n",
    "      \n",
    "    # creates SMTP session \n",
    "    s = smtplib.SMTP_SSL('smtp.libero.it', 465) \n",
    "      \n",
    "    # start TLS for security \n",
    "    #s.starttls() \n",
    "      \n",
    "    # Authentication \n",
    "    s.login(fromaddr, \"Amedeo98\") \n",
    "      \n",
    "    # Converts the Multipart msg into a string \n",
    "    text = msg.as_string() \n",
    "      \n",
    "    # sending the mail \n",
    "    s.sendmail(fromaddr, toaddr, text) \n",
    "      \n",
    "    # terminating the session \n",
    "    s.quit() \n",
    "\n",
    "def elab_sapflow():\n",
    "    \n",
    "    #do equation\n",
    "    df_night=dfn[dfn.a_650<=10]\n",
    "    df_night['date_night']=pd.to_datetime(df_night['timestamp'],unit='s')\n",
    "    df_night['date_night'] = df_night['date_night'].dt.strftime('%d%m%Y')\n",
    "    df_night['dTon']= df_night['Theat_1c']-df_night['Tref_1c']\n",
    "    df_night ['dToff']=df_night['Theat_0c']-df_night['Tref_0c']\n",
    "    df_night['dTindex']=df_night['dTon']-df_night['dToff']\n",
    "    \n",
    "    \n",
    "    dfn['dTon']= dfn['Theat_1c']-dfn['Tref_1c']\n",
    "    dfn['dToff']=dfn['Theat_0c']-dfn['Tref_0c']\n",
    "    dfn['dTindex']=dfn['dTon']-dfn['dToff']\n",
    "    \n",
    "    for j in range (0,len(dfn)):\n",
    "            \n",
    "            day_n=pd.to_datetime(dfn.loc[j,'timestamp'],unit='s').strftime('%d%m%Y')\n",
    "            #.strftime('%d%m%Y')\n",
    "            df_day=df_night[df_night['date_night']==day_n]\n",
    "            dTmax=df_day['dTindex'].max()\n",
    "            dfn.loc[j,'sap_flow_density_raw']=12.95*((dTmax/(dfn.loc[j,'dTindex'])-1))*10 #transf from l dm-2 h-1 to g cm-2 h-1\n",
    "            if dfn.loc[j,'sap_flow_density_raw'] <0:\n",
    "                dfn.loc[j,'sap_flow_density_raw']=0\n",
    "    \n",
    "    dfn['sap_flow_density']=dfn.loc[0:len(dfn),'sap_flow_density_raw'].rolling(window=4).mean() # rolling mean of interpolated data\n",
    "    \n",
    "    # granier equation\n",
    "    #dfn['dTindex']=dfn['Theat_1c']-dfn['Tref_1c']\n",
    "    #for j in range (25,len(dfn)):\n",
    "        #dTmax=dfn.loc[j-25:j,'dTindex'].max()\n",
    "        #dfn.loc[j,'sap_flow_density']=118.99*10000*((dTmax/(dfn.loc[j,'dTindex'])-1))/3600 #transf from g m-2 s-1 to g cm-2 h-1\n",
    "        \n",
    "    dfn['stem_humidity']=dfn.freq # to be upgraded by shahla\n",
    "    \n",
    "    \n",
    "\n",
    "def elab_growth():\n",
    "    \n",
    "    dfn_night=dfn[dfn['a_650']==0]# select only night values\n",
    "    dfn['growth_sensor_night']=dfn_night['growth_sensor_c']\n",
    "    avg_g=dfn['growth_sensor_night'].median()# calculate median\n",
    "    std_g=dfn['growth_sensor_night'].std()#calculate std\n",
    "    \n",
    "    for j in range (0,len(dfn)):\n",
    "            if dfn.loc[j,'growth_sensor_night']>avg_g+2*std_g or dfn.loc[j,'growth_sensor_night']<avg_g-2*std_g: # correct for numbers outside +- 2*std\n",
    "                dfn.loc[j,'growth_sensor_night']=avg_g #replace outliers with median \n",
    "    dfn.growth_sensor_night.interpolate(method='pad',axis=0, inplace=True) #interpolation of missing data NaN\n",
    "    dfn['growth_roll']=dfn.loc[0:len(dfn),'growth_sensor_night'].rolling(window=200).mean() # rolling mean of interpolated data\n",
    "    dfn['growth_roll_diff']=dfn['growth_roll'].diff() # derivative (growth) of the distance\n",
    "    dfn.loc[dfn.growth_roll_diff>0,'growth_roll_diff']=0  #to be applied in case we want non-negative growth\n",
    "    \n",
    "    dfn['radial_growth']=-dfn['growth_roll_diff'].cumsum() # cumulative growth (negative since growth equal less distance from trunk)\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "def elab_stem_humidity():\n",
    "    #dfn['stem_humidity']=((dfn.freq-(-74.149*dfn['Tref_0c']) + 33165)*-0.0001+1.9581)*100 # according to shahla\n",
    "    a=-72.768*dfn['Tref_0c'] + 27392 # probe in water sensitivity\n",
    "    dfn['stem_humidity']=((1-(dfn.freq-a)/a))*100 # this is as reference to water 100%\n",
    "      \n",
    "\n",
    "def elab_light ():\n",
    "   \n",
    "\n",
    "    dfn.loc[dfn.a_610 >65532,'a_610']=np.nan\n",
    "    dfn.loc[dfn.a_680 >65532,'a_680']=np.nan\n",
    "    dfn.loc[dfn.a_730 >65532,'a_730']=np.nan\n",
    "    dfn.loc[dfn.a_760 >65532,'a_760']=np.nan\n",
    "    dfn.loc[dfn.a_810 >65532,'a_810']=np.nan\n",
    "    dfn.loc[dfn.a_860 >65532,'a_860']=np.nan\n",
    "    dfn.loc[dfn.a_450 >65532,'a_450']=np.nan\n",
    "    dfn.loc[dfn.a_500 >65532,'a_500']=np.nan\n",
    "    dfn.loc[dfn.a_550 >65532,'a_550']=np.nan\n",
    "    dfn.loc[dfn.a_570 >65532,'a_570']=np.nan\n",
    "    dfn.loc[dfn.a_600 >65532,'a_600']=np.nan\n",
    "    dfn.loc[dfn.a_650 >65532,'a_650']=np.nan\n",
    "    \n",
    "    dfn['ndvi_raw']=(dfn.a_760-dfn.a_680)/(dfn.a_760+dfn.a_680)\n",
    "    dfn.ndvi_raw.interpolate(method='pad',axis=0, inplace=True) #interpolation of missing data NaN\n",
    "    dfn.loc[dfn.ndvi_raw <0,'ndvi_raw']=0\n",
    "    dfn['ndvi']=dfn.loc[0:len(dfn),'ndvi_raw'].rolling(window=4).mean() # rolling mean of interpolated data\n",
    "    \n",
    "    dfn['green_red_raw']=(dfn.a_570-dfn.a_680)/(dfn.a_570+dfn.a_680)\n",
    "    dfn.green_red_raw.interpolate(method='pad',axis=0, inplace=True) #interpolation of missing data NaN\n",
    "    dfn.loc[dfn.green_red_raw <0,'green_red_raw']=0\n",
    "    dfn['green_red']=dfn.loc[0:len(dfn),'green_red_raw'].rolling(window=4).mean() # rolling mean of interpolated data\n",
    "    \n",
    "def ftp_send(file_ofidia2):\n",
    "    ftp = FTP('ftp.naturetalkers.altervista.org')  \n",
    "    ftp.login('naturetalkers', 'nature2017')\n",
    "    \n",
    "    with open(file_ofidia2+'.csv', \"rb\") as f:\n",
    "        ftp.storbinary('STOR ' + file_ofidia2+'.txt', f) \n",
    "    ftp.quit()\n",
    "    \n",
    "    \n",
    "#READ THE CLOUD    \n",
    "\n",
    "flag_bat=1\n",
    "cloudID_ff='CF200001'\n",
    "cloudID_tt='C0200114'\n",
    "url_proj='OFIDIA2'\n",
    "url_site='CESINE'\n",
    "\n",
    "TTcloud_tt=url_site+cloudID_tt\n",
    "TTcloud_ff=url_site+cloudID_ff\n",
    "cols=['timestamp','tree_talker', 'sap_flow_density','stem_humidity','radial_growth','ndvi','green_red','leaf_temperature','air_temperature','rel_air_humidity','gas_co2','gas_o3','gas_pm2.5','gas_pm10','flame_pulses','flame_flag','trunk_axis_movement']\n",
    "\n",
    "dfn_cum=pd.DataFrame(columns=cols) \n",
    "dfn_day=pd.DataFrame(columns=cols) \n",
    "\n",
    "d=dt.datetime.now()\n",
    "old_day=d.strftime('%d.%m.%Y')\n",
    "        \n",
    "        \n",
    "while True:\n",
    "  \n",
    "        \n",
    "        t0=time.time()\n",
    "        ts = str(int(time.time()))\n",
    "       \n",
    "       \n",
    "        \n",
    "        \n",
    "        while True :\n",
    "            try:\n",
    "                    print (\"job start at ... \",dt.datetime.now())\n",
    "                    url_tt = 'http://naturetalkers.altervista.org/'+cloudID_tt+'/ttcloud.txt'\n",
    "                    url_ff = 'http://naturetalkers.altervista.org/'+cloudID_ff+'/ttcloud.txt'\n",
    "                    df_tt=pd.read_csv(url_tt, sep=',',engine='python',header=None)\n",
    "                    df_ff=pd.read_csv(url_ff, sep=',',engine='python',header=None)\n",
    "            except:\n",
    "                    print (\"altervista server failure .....\")\n",
    "                    time.sleep(6)\n",
    "                    pass\n",
    "            else:\n",
    "                    break\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "       \n",
    "        \n",
    "        \n",
    "        dtt=pd.read_csv(url_proj+'/'+url_site+'/'+url_site+'_names.csv', sep=',',index_col=False, engine='python',header=0)\n",
    "        \n",
    "\n",
    "        dtt.ID=dtt.ID.astype(str)\n",
    "        dtt.IDF=dtt.IDF.astype(str)\n",
    "        \n",
    "        print ('Data retrieval time seconds .....',time.time()-t0)\n",
    "        t1=time.time()\n",
    "               \n",
    "        #CREATE DATAFRAME FOR TT AND TT FIRE\n",
    "        \n",
    "        a=[]\n",
    "        col0=df_tt.iloc[:,0].to_list()\n",
    "        col1=df_tt.iloc[:,1].to_list() \n",
    "        for i in range (len(col1)):\n",
    "                a.append(col1[i].split(';'))\n",
    "        dfraw=pd.DataFrame(a)\n",
    "        df_tt=dfraw[480*31:len(dfraw)] # we take data after 240 hours of stabilizatio (10 days)\n",
    "        df_tt.reset_index(drop=True,inplace=True)\n",
    "        \n",
    "        b=[]\n",
    "        col0=df_ff.iloc[:,0].to_list()\n",
    "        col1=df_ff.iloc[:,1].to_list() \n",
    "        for i in range (len(col1)):\n",
    "                b.append(col1[i].split(';'))\n",
    "        dfraw=pd.DataFrame(b)\n",
    "        df_ff=dfraw[480*31:len(dfraw)] # we take data after 240 hours of stabilizatio (10 days)\n",
    "        df_ff.reset_index(drop=True,inplace=True)\n",
    "         \n",
    "        \n",
    "               \n",
    "               \n",
    "        \n",
    "        #TREE TALKER SECTION\n",
    "        \n",
    "        #CLEANING DATAFRAME GENERATING COMBINED STRING 49 AND 4D FOR ID of treetalkers\n",
    "        \n",
    "        #t2=time.time()\n",
    "        names_tt=dtt.ID\n",
    "        names_ff=dtt.IDF\n",
    "        \n",
    "        #dfn_cum.to_csv (url_names+'_'+day+'.csv',index=False)\n",
    "        df_Vbat=pd.DataFrame(columns=['ID','date','Vbat'])\n",
    "\n",
    "\n",
    "        for i in range (0,len(dtt)):\n",
    "                dfn_day=pd.DataFrame(columns=cols)\n",
    "                dfx=df_tt[df_tt.iloc[:,0]==names_tt[i]]\n",
    "                if len(dfx)==0:\n",
    "                    print (names_tt[i], 'missing')\n",
    "                    row_bat=[names_tt[i],old_day,'missing']                 \n",
    "                    df_Vbat.loc[len(df_Vbat)]=row_bat\n",
    "                    continue\n",
    "            \n",
    "                dfn1=dfx[dfx.iloc[:,2]=='4D']\n",
    "                col_delete=[1,2,21,22,23,24,25,26,27,28,29] \n",
    "                dfn1.drop(col_delete,axis=1,inplace =True)\n",
    "                col1=['tree_talker','timestamp','Tref_0','Theat_0','growth_sensor',\n",
    "                'adc_bandgap','bits','rel_air_humidity','air_temperature','g_zmean','g_zstd','g_ymean','g_ystd','g_xmean','g_xstd','Tref_1','Theat_1','freq','adc_Vbat']\n",
    "                dfn1.columns=col1\n",
    "                dfn1.drop_duplicates(subset=None, inplace=True)\n",
    "                dfn1.reset_index(drop=True, inplace=True)\n",
    "                \n",
    "                dfn2=dfx[dfx.iloc[:,2]=='49']\n",
    "                col_delete=[1,2,18,19,20,21,22,23,24,25,26,27,28,29] \n",
    "                dfn2.drop(col_delete,axis=1,inplace =True)\n",
    "                col2=['tree_talker','timestamp','a_610','a_680','a_730','a_760','a_810','a_860','a_450','a_500','a_550','a_570','a_600','a_650','integration_time','gain']\n",
    "                dfn2.columns=col2\n",
    "                dfn2.drop_duplicates(subset=None, inplace=True)\n",
    "                dfn2.reset_index(drop=True, inplace=True)\n",
    "                \n",
    "                dfn=pd.merge(dfn1,dfn2,on=['tree_talker','timestamp'])\n",
    "                dfn.drop_duplicates(subset=None, inplace=True)\n",
    "                dfn.reset_index(drop=True, inplace=True)\n",
    "                dfn.timestamp=dfn.timestamp.astype(int)\n",
    "                dfn.timestamp=round(dfn.timestamp/10)*10\n",
    "                for j in dfn.columns[2:32]:\n",
    "                    dfn[j]=dfn[j].astype(float)\n",
    "               \n",
    "                dfn['timestamp']=dfn['timestamp'].astype(int)\n",
    "                dfn.to_csv(url_proj+'/'+url_site+'/'+url_site+'_'+names_tt[i]+'_raw.csv',index=False)\n",
    "                transf()\n",
    "                dfn.to_csv(url_proj+'/'+url_site+'/'+url_site+'_'+names_tt[i]+'_transf.csv',index=False)\n",
    "                #print (dfn.loc[len(dfn)-1,'timestamp'],dfn.loc[len(dfn)-1,'date'])\n",
    "               \n",
    "                Vbat_show()\n",
    "                elab_sapflow()\n",
    "                elab_growth()\n",
    "                elab_stem_humidity()\n",
    "                elab_light()\n",
    "                \n",
    "                row_bat=[dfn.loc[len(dfn)-1,'tree_talker'],dfn.loc[len(dfn)-1,'date'],dfn.loc[len(dfn)-1,'Vbat_c']]          \n",
    "                df_Vbat.loc[len(df_Vbat)]=row_bat\n",
    "               \n",
    "                dfn.to_csv(url_proj+'/'+url_site+'/'+url_site+'_'+names_tt[i]+'_elab.csv',index=False)\n",
    "                \n",
    "                dfn_c=dfn[['tree_talker', 'timestamp','sap_flow_density','stem_humidity','radial_growth','ndvi','green_red','air_temperature','rel_air_humidity','trunk_axis_movement']]\n",
    "                dfn_c.reset_index(drop=True, inplace=True)\n",
    "                #print ('TT data elaboration end after seconds .....',time.time()-t1)\n",
    "                #dfn_cum.loc[len(dfn_cum)]=dfn_c.loc[len(dfn)-1]\n",
    "                \n",
    "        \n",
    "        \n",
    "        \n",
    "                # TT FIRE SECTION  \n",
    "                #CLEANING DATAFRAME GENERATING TT FIRE STRING\n",
    "        \n",
    "                t2=time.time()        \n",
    "                \n",
    "                dfx_ff=df_ff[df_ff.iloc[:,0]==names_ff[i]]            \n",
    "                dfn1=dfx_ff[dfx_ff.iloc[:,2]=='70']\n",
    "                \n",
    "                if len(dfn1)==0:\n",
    "                    print (names_ff[i], 'missing')\n",
    "                    row_bat=[names_ff[i],old_day,'missing']                 \n",
    "                    df_Vbat.loc[len(df_Vbat)]=row_bat\n",
    "                    continue\n",
    "                    \n",
    "                col_delete=[1,2,18,19,20,21,22,23,24,25,26,27,28,29] \n",
    "                dfn1.drop(col_delete,axis=1,inplace =True)\n",
    "            \n",
    "            \n",
    "        \n",
    "            \n",
    "            \n",
    "                col1=['tree_talker_ff','timestamp','bits','rel_air_humidity_ff','air_temperature_ff','Vbat_ff','flame_pulses','UVTron_sampling_time','gas_pm2.5','gas_pm10','gas_sampling_time','gas_co2','gas_o3','leaf_temperature','air_temperature_IR','IR_samples']\n",
    "                dfn1.columns=col1\n",
    "                dfn1.drop_duplicates(subset=None, inplace=True)\n",
    "                dfn1.reset_index(drop=True, inplace=True)\n",
    "                dfn1.timestamp=dfn1.timestamp.astype(int)\n",
    "                dfn1.timestamp=round(dfn1.timestamp/10)*10\n",
    "                dfn1.timestamp=dfn1.timestamp.astype(int)\n",
    "                \n",
    "                \n",
    "                for j in dfn1.columns[2:15]:\n",
    "                        dfn1[j]=dfn1[j].astype(float)    \n",
    "            \n",
    "                \n",
    "                \n",
    "                dfn1.to_csv(url_proj+'/'+url_site+'/'+url_site+'_'+names_ff[i]+'_raw.csv',index=False)\n",
    "                transf_ff()\n",
    "                \n",
    "                if dfn1.loc[len(dfn1)-1,'flame_pulses']>100:\n",
    "                    dfn1.loc[len(dfn1)-1,'flame_flag']=1\n",
    "                else:\n",
    "                    dfn1.loc[len(dfn1)-1,'flame_flag']=0\n",
    "                \n",
    "                dfn1.to_csv(url_proj+'/'+url_site+'/'+url_site+'_'+names_ff[i]+'_transf.csv',index=False)\n",
    "                \n",
    "               \n",
    "                #dfn1.to_csv(url_site+'_ff_'+i+'elab.csv',index=False)\n",
    "                dfn_tot = pd.merge_asof(dfn1.sort_values('timestamp'), dfn_c.sort_values('timestamp'), on='timestamp')\n",
    "                dfn_tot=dfn_tot[cols]\n",
    "                dfn_tot.to_csv(url_proj+'/'+url_site+'/'+url_site+'_'+names_tt[i]+'_tot.csv',index=False)\n",
    "            \n",
    "            \n",
    "                d=dt.datetime.now()\n",
    "                day=d.strftime('%d.%m.%Y')\n",
    "                last_date = pd.to_datetime(dfn_tot.loc[len(dfn_tot)-1,'timestamp'],unit='s')\n",
    "    \n",
    "                last_date=last_date.strftime('%d.%m.%Y')\n",
    "                #dfn_cum.loc[len(dfn_cum)]=dfn_tot.loc[len(dfn_tot)-1]\n",
    "                \n",
    "               \n",
    "                dfn_day.loc[len(dfn_day)]=dfn_tot.loc[len(dfn_tot)-1]\n",
    "                \n",
    "                file_ofidia2 =url_proj+'/'+url_site+'/'+url_site+'_'+last_date\n",
    "                if os.path.exists(file_ofidia2+'.csv'):\n",
    "                    bol=False\n",
    "                else:\n",
    "                    bol=True\n",
    "                with open(file_ofidia2+'.csv','a+') as f:\n",
    "                           dfn_day.to_csv(f,index=False,header=bol)\n",
    "                \n",
    "              \n",
    "                \n",
    "                #print ('TT Fire  data elaboration end after seconds .....',time.time()-t2))\n",
    "                \n",
    "        \n",
    "        \n",
    "                \n",
    "        #dfn_cum.to_csv(url_names+'_'+day+'.csv',index=False)\n",
    "        df_Vbat.to_csv(url_proj+'/'+url_site+'/'+url_site+'_BAT_'+day+'.csv',index=False)\n",
    "        \n",
    "        if day != old_day or flag_bat==1:# flag 1 only when you start script for the first time\n",
    "            Vbat_mail()\n",
    "            old_day=day\n",
    "            flag_bat=0\n",
    "        \n",
    "        #with open(url_proj+'/'+url_site+'/'+url_site+'_'+day+'.csv','a+') as f:\n",
    "                #dfn_cum.to_csv(f,index=False,header=None)\n",
    "        \n",
    "        \n",
    "        ftp_send(file_ofidia2)\n",
    "        \n",
    "        print ('TT total elaboration time seconds .....',time.time()-t0)\n",
    "        \n",
    "        #plt.figure(figsize=(15,4))\n",
    "        #plt.title(i)\n",
    "        #plt.xlim(1596492000,1596751200)\n",
    "        #plt.plot(dfn1.timestamp,dfn1.air_temperature_IR,color='b')\n",
    "        \n",
    "        print('Waiting next job .......')\n",
    "        time.sleep(3600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
