{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TT data analytics by RV ver1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1000\"\n",
       "            height=\"1000\"\n",
       "            src=\"https://rikvalentini.wixsite.com/naturetalkers\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fd819d8b350>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from IPython.display import Javascript\n",
    "#Javascript(\"Jupyter.notebook.execute_cells([2,3])\")\n",
    "from IPython.display import IFrame\n",
    "\n",
    "IFrame(src='https://rikvalentini.wixsite.com/naturetalkers', width=1000, height=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INPUT YOUR TT CLOUD NUMBER AND OPERATION MODE\n",
    "> loop ON mode if you want to automatic updates every hour your data files, otherwise for single run do not check the box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4505e2076bec432a9add87f8cf12eb1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='Input TTCLoud serial number')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a18f1c6dd9349e485c90de1f53aac1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Checkbox(value=False, description='Loop ON', indent=False)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce738c4ad0844bc881daf689571a248f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='time cycle in seconds')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import FileUpload\n",
    "from IPython.display import Javascript\n",
    "\n",
    "TT_cloud=widgets.Text('Input TTCLoud serial number')\n",
    "display (TT_cloud)\n",
    "\n",
    "loop_on=widgets.Checkbox(\n",
    "    value=False,\n",
    "    description='Loop ON',\n",
    "    disabled=False,\n",
    "    indent=False\n",
    ")\n",
    "\n",
    "display (loop_on)\n",
    "time_cycle=widgets.Text('time cycle in seconds')\n",
    "display (time_cycle)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INPUT YOUR TTs SERIAL NUMBERS\n",
    ">Prepare an excel file with one column containing the TTs serial numbers \n",
    ">with the column name 'ID' and save as .csv file (i.e C0200114.csv)- The directory of this file will be the repositiry of all the elaborated data for this Cloud\n",
    "\n",
    "\n",
    "\n",
    "|  ID  |\n",
    "|-|\n",
    "|   52060652  |\n",
    "|   52060669  |\n",
    "|   52060671  |\n",
    "|   52060656  |\n",
    "|   52060668  |\n",
    "|   52060664  |\n",
    "|   52060667  |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1de2fff7239418aa887d2f389b688d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileChooser(path='/Users', filename='', title='HTML(value='', layout=Layout(display='none'))', show_hidden='Faâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ipyfilechooser import FileChooser\n",
    "fc = FileChooser('/Users/')\n",
    "display(fc)\n",
    "# fc.selected  is file path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input the Email addresses to send TTs battery report \n",
    "###### insert email addresses separated by commas (i.e. rik@unitus.it, rikvalentini@gmail.com,....)\n",
    "> (skip it if you do not need this function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d3f09ffc0e54319aeebeb2aecda8113",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='your mail', description='FROM')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0f5df0109604ce3a6c9419383cd36fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='i.e. rik@unitus.it,...', description='TO')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19347540515449ae9805a156bf9c655e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='i.e. smtp.gmail.com', description='SMTP server')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50692230a5474b29805a5d0a4db305c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='i.e. 465', description='SMTP port')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27b3238ed75d41c2aff155ca12da7911",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description='Password')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f946c6a4dc8b45bfa008b44530c68b21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Checkbox(value=False, description='Send mail', indent=False)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "193fb98107d34e33b187d69e9b601e93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Checkbox(value=False, description='Store mail addr', indent=False)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mail_addr_from=widgets.Text(description='FROM',value='your mail')\n",
    "display (mail_addr_from)\n",
    "mail_addr_to=widgets.Text(description='TO',value='i.e. rik@unitus.it,...')\n",
    "display (mail_addr_to)\n",
    "# mail_list = mail_addr.value.split(',') # this create a list of mail addresses\n",
    "\n",
    "mail_smtp=widgets.Text(description='SMTP server',value='i.e. smtp.gmail.com')\n",
    "display (mail_smtp)\n",
    "mail_port=widgets.Text(description='SMTP port',value='i.e. 465')\n",
    "display (mail_port)\n",
    "mail_pw=widgets.Text(description='Password',value='')\n",
    "display (mail_pw)\n",
    "\n",
    "mail_on=widgets.Checkbox(\n",
    "    value=False,\n",
    "    description='Send mail',\n",
    "    disabled=False,\n",
    "    indent=False\n",
    ")\n",
    "\n",
    "mail_store=widgets.Checkbox(\n",
    "    value=False,\n",
    "    description='Store mail addr',\n",
    "    disabled=False,\n",
    "    indent=False\n",
    ")\n",
    "\n",
    "\n",
    "display (mail_on)\n",
    "display (mail_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "job start at ...  2020-09-21 17:24:03.375240\n",
      "Data retrieval time seconds ..... 6.800644874572754\n",
      "52060628 3.72 21/09/2020/12:00:00\n",
      "52060582 3.87 21/09/2020/13:00:00\n",
      "52060611 3.9 21/09/2020/15:00:00\n",
      "52060614 missing\n",
      "52060591 3.81 21/09/2020/14:00:00\n",
      "52060619 3.78 21/09/2020/06:00:00\n",
      "52060622 3.83 21/09/2020/13:00:00\n",
      "52060641 3.95 21/09/2020/15:00:00\n",
      "52060594 3.76 21/09/2020/15:00:00\n",
      "52060595 3.74 21/09/2020/12:00:00\n",
      "52060584 3.21 17/09/2020/15:00:00\n",
      "52060596 3.87 21/09/2020/15:00:00\n",
      "52060607 3.88 21/09/2020/14:00:00\n",
      "52060593 3.98 21/09/2020/14:00:00\n",
      "52060597 3.76 21/09/2020/14:00:00\n",
      "52060600 3.86 21/09/2020/14:00:00\n",
      "52060616 4.15 06/09/2020/12:00:00\n",
      "52060569 4.06 15/09/2020/00:00:00\n",
      "52060589 3.32 28/08/2020/10:00:00\n",
      "52060637 4.01 09/09/2020/06:00:00\n",
      "52060604 3.84 21/09/2020/13:00:00\n",
      "52060577 3.79 21/09/2020/13:00:00\n",
      "52060571 3.76 21/09/2020/10:00:00\n",
      "52060573 3.73 21/09/2020/10:00:00\n",
      "52060648 3.96 16/09/2020/23:00:00\n",
      "52060620 3.84 20/09/2020/00:00:00\n",
      "52060575 4.02 13/09/2020/19:00:00\n",
      "52060632 3.78 21/09/2020/06:00:00\n",
      "52060592 3.95 19/09/2020/12:00:00\n",
      "52060624 4.02 09/09/2020/19:00:00\n",
      "TT total elaboration time seconds ..... 73.67117714881897\n",
      "job ended\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import time\n",
    "import math\n",
    "from ftplib import FTP\n",
    "import csv\n",
    "import dask.dataframe as dd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import smtplib \n",
    "from email.mime.multipart import MIMEMultipart \n",
    "from email.mime.text import MIMEText \n",
    "from email.mime.base import MIMEBase \n",
    "from email import encoders  \n",
    "# Set it to None to display all columns in the dataframe\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 5000)\n",
    "pd.options.mode.chained_assignment = None \n",
    "\n",
    "\n",
    "\n",
    "#Data transformation in physical units\n",
    "def transf():\n",
    "    dfn['Tref_0c']=127.6-0.006045*dfn['Tref_0'] + 1.26E-07*dfn['Tref_0']**2 -1.15E-12*dfn['Tref_0']**3\n",
    "    dfn['Tref_1c']=127.6-0.006045*dfn['Tref_1'] + 1.26E-07*dfn['Tref_1']**2 -1.15E-12*dfn['Tref_1']**3\n",
    "    dfn['Theat_0c']=127.6-0.006045*dfn['Theat_0'] + 1.26E-07*dfn['Theat_0']**2 -1.15E-12*dfn['Theat_0']**3\n",
    "    dfn['Theat_1c']=127.6-0.006045*dfn['Theat_1'] + 1.26E-07*dfn['Theat_1']**2 -1.15E-12*dfn['Theat_1']**3\n",
    "    #dfn['growth_sensor_c']=194.856731-0.008274771*dfn.growth_sensor+1.63685E-07*dfn.growth_sensor**2-1.58251E-12*dfn.growth_sensor**3+ 5.96455E-18*dfn.growth_sensor**4\n",
    "    dfn['growth_sensor_c']=-0.0006*dfn['growth_sensor']+61.079\n",
    "    dfn['angle_mean_c']=np.arctan((dfn['g_xmean']**2+(dfn['g_ymean']**2)/dfn['g_zmean'])**0.5)*90/(np.pi/2)\n",
    "    dfn['trunk_axis_movement']=dfn['g_xstd']+dfn['g_ystd']+dfn['g_zstd']\n",
    "    dfn['Vbat_c']= round(2*1100*dfn['adc_Vbat']/dfn['adc_bandgap']/1000,2)\n",
    "    dfn['date'] = pd.to_datetime(dfn['timestamp'],unit='s')\n",
    "    #dfn['date'].dt.tz_localize('utc').dt.tz_convert('Europe/Rome') in case of usimng EU time\n",
    "    dfn['date'] = dfn['date'].dt.strftime('%d/%m/%Y/%H:%M:%S')\n",
    "    dfn['air_temperature'] = dfn['air_temperature']/10\n",
    "\n",
    "def transf_ff():\n",
    "    dfn1['air_temperature_ff'] = dfn1['air_temperature_ff']/10\n",
    "    dfn1['gas_co2']=dfn1['gas_co2']*1.25-500. # see MHZ19B datasheet 0-2000 ppm --> 400 - 2000 mVolts\n",
    "    dfn1['gas_o3']=dfn1['gas_o3']*-0.076+390 # see mq131 (low concebration manual) 10 - 200 ppb  ---> 5000 - 2500 mVolts\n",
    "    dfn1['gas_o3']=dfn1['gas_o3']*48/24.45 # conversion in ug m-3\n",
    "    #dfn1['leaf_temperature']=dfn1['leaf_temperature']/210 -273.15 # conversione 210 counts/K\n",
    "    dfn1['leaf_temperature']=25+(dfn1['leaf_temperature']-64500)/210  # conversione 210 counts/K con offset di 64500@25Â°C see excelitas data sheet TPS 1S 1051\n",
    "    dfn1['air_temperature_IR']=25+ (dfn1['air_temperature_IR']-8200)/90  # conversione 90 counts/K con offset di 8200@25Â°C\n",
    "    dfn1['date'] = pd.to_datetime(dfn1['timestamp'],unit='s')\n",
    "    #dfn['date'].dt.tz_localize('utc').dt.tz_convert('Europe/Rome') in case of usimng EU time\n",
    "    \n",
    "    \n",
    "\n",
    "#Showing batteries voltage\n",
    "def Vbat_show():\n",
    "    print (names_tt[i],dfn.loc[len(dfn)-1,'Vbat_c'],dfn.loc[len(dfn)-1,'date'])\n",
    "    #dt.datetime.fromtimestamp(1596725594).strftime('%Y-%m-%d %H:%M:%S %j' )\n",
    "\n",
    "#Sending report check\n",
    "def Vbat_mail():\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    toaddr = data_mail[1].split(',') # this create a list of mail addresses\n",
    "    fromaddr = data_mail[0]\n",
    "    smtp=data_mail[2]\n",
    "    port=data_mail[3]\n",
    "    pw=data_mail[4]\n",
    "    \n",
    "    \n",
    "     # instance of MIMEMultipart \n",
    "    msg = MIMEMultipart() \n",
    "      \n",
    "    # storing the senders email address   \n",
    "    msg['From'] = fromaddr \n",
    "      \n",
    "    # storing the receivers email address  \n",
    "  \n",
    "    msg['To'] = ', '.join(toaddr)\n",
    "    # storing the subject  \n",
    "    msg['Subject'] = cloudID_tt\n",
    "      \n",
    "    # string to store the body of the mail \n",
    "    body = \"Battery test\"\n",
    "      \n",
    "    # attach the body with the msg instance \n",
    "    msg.attach(MIMEText(body, 'plain')) \n",
    "      \n",
    "    # open the file to be sent  \n",
    "    filename = url_proj+'/'+cloudID_tt+'_BAT_'+day+'.csv'\n",
    "    attachment = open(filename, \"rb\") \n",
    "      \n",
    "    # instance of MIMEBase and named as p \n",
    "    p = MIMEBase('application', 'octet-stream') \n",
    "      \n",
    "    # To change the payload into encoded form \n",
    "    p.set_payload((attachment).read()) \n",
    "      \n",
    "    # encode into base64 \n",
    "    encoders.encode_base64(p) \n",
    "       \n",
    "    p.add_header('Content-Disposition', \"attachment; filename= %s\" % cloudID_tt+'_BAT_'+day+'.csv') \n",
    "      \n",
    "    # attach the instance 'p' to instance 'msg' \n",
    "    msg.attach(p) \n",
    "      \n",
    "    # creates SMTP session \n",
    "    s = smtplib.SMTP_SSL(smtp, port) \n",
    "      \n",
    "    # start TLS for security \n",
    "    #s.starttls() \n",
    "      \n",
    "    # Authentication \n",
    "    s.login(fromaddr, pw) \n",
    "      \n",
    "    # Converts the Multipart msg into a string \n",
    "    text = msg.as_string() \n",
    "      \n",
    "    # sending the mail \n",
    "    s.sendmail(fromaddr, toaddr, text) \n",
    "      \n",
    "    # terminating the session \n",
    "    s.quit() \n",
    "\n",
    "def elab_sapflow():\n",
    "    \n",
    "    #do equation\n",
    "    df_night=dfn[dfn.a_650<=10]\n",
    "    df_night['date_night']=pd.to_datetime(df_night['timestamp'],unit='s')\n",
    "    df_night['date_night'] = df_night['date_night'].dt.strftime('%d%m%Y')\n",
    "    df_night['dTon']= df_night['Theat_1c']-df_night['Tref_1c']\n",
    "    df_night ['dToff']=df_night['Theat_0c']-df_night['Tref_0c']\n",
    "    df_night['dTindex']=df_night['dTon']-df_night['dToff']\n",
    "    \n",
    "    \n",
    "    dfn['dTon']= dfn['Theat_1c']-dfn['Tref_1c']\n",
    "    dfn['dToff']=dfn['Theat_0c']-dfn['Tref_0c']\n",
    "    dfn['dTindex']=dfn['dTon']-dfn['dToff']\n",
    "    \n",
    "    for j in range (0,len(dfn)):\n",
    "            \n",
    "            day_n=pd.to_datetime(dfn.loc[j,'timestamp'],unit='s').strftime('%d%m%Y')\n",
    "            #.strftime('%d%m%Y')\n",
    "            df_day=df_night[df_night['date_night']==day_n]\n",
    "            dTmax=df_day['dTindex'].max()\n",
    "            dfn.loc[j,'sap_flow_density_raw']=12.95*((dTmax/(dfn.loc[j,'dTindex'])-1))*10 #transf from l dm-2 h-1 to g cm-2 h-1\n",
    "            if dfn.loc[j,'sap_flow_density_raw'] <0:\n",
    "                dfn.loc[j,'sap_flow_density_raw']=0\n",
    "    \n",
    "    dfn['sap_flow_density']=dfn.loc[0:len(dfn),'sap_flow_density_raw'].rolling(window=4).mean() # rolling mean of interpolated data\n",
    "    \n",
    "    # granier equation\n",
    "    #dfn['dTindex']=dfn['Theat_1c']-dfn['Tref_1c']\n",
    "    #for j in range (25,len(dfn)):\n",
    "        #dTmax=dfn.loc[j-25:j,'dTindex'].max()\n",
    "        #dfn.loc[j,'sap_flow_density']=118.99*10000*((dTmax/(dfn.loc[j,'dTindex'])-1))/3600 #transf from g m-2 s-1 to g cm-2 h-1\n",
    "        \n",
    "    dfn['stem_humidity']=dfn.freq # to be upgraded by shahla\n",
    "    \n",
    "    \n",
    "\n",
    "def elab_growth():\n",
    "    \n",
    "    dfn_night=dfn[dfn['a_650']==0]# select only night values\n",
    "    dfn['growth_sensor_night']=dfn_night['growth_sensor_c']\n",
    "    avg_g=dfn['growth_sensor_night'].median()# calculate median\n",
    "    std_g=dfn['growth_sensor_night'].std()#calculate std\n",
    "    \n",
    "    for j in range (0,len(dfn)):\n",
    "            if dfn.loc[j,'growth_sensor_night']>avg_g+2*std_g or dfn.loc[j,'growth_sensor_night']<avg_g-2*std_g: # correct for numbers outside +- 2*std\n",
    "                dfn.loc[j,'growth_sensor_night']=avg_g #replace outliers with median \n",
    "    dfn.growth_sensor_night.interpolate(method='pad',axis=0, inplace=True) #interpolation of missing data NaN\n",
    "    dfn['growth_roll']=dfn.loc[0:len(dfn),'growth_sensor_night'].rolling(window=200).mean() # rolling mean of interpolated data\n",
    "    dfn['growth_roll_diff']=dfn['growth_roll'].diff() # derivative (growth) of the distance\n",
    "    dfn.loc[dfn.growth_roll_diff>0,'growth_roll_diff']=0  #to be applied in case we want non-negative growth\n",
    "    \n",
    "    dfn['radial_growth']=-dfn['growth_roll_diff'].cumsum() # cumulative growth (negative since growth equal less distance from trunk)\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "def elab_stem_humidity():\n",
    "    #dfn['stem_humidity']=((dfn.freq-(-74.149*dfn['Tref_0c']) + 33165)*-0.0001+1.9581)*100 # according to shahla\n",
    "    a=-72.768*dfn['Tref_0c'] + 27392 # probe in water sensitivity\n",
    "    dfn['stem_humidity']=((1-(dfn.freq-a)/a))*100 # this is as reference to water 100%\n",
    "      \n",
    "\n",
    "def elab_light ():\n",
    "   \n",
    "\n",
    "    dfn.loc[dfn.a_610 >65532,'a_610']=np.nan\n",
    "    dfn.loc[dfn.a_680 >65532,'a_680']=np.nan\n",
    "    dfn.loc[dfn.a_730 >65532,'a_730']=np.nan\n",
    "    dfn.loc[dfn.a_760 >65532,'a_760']=np.nan\n",
    "    dfn.loc[dfn.a_810 >65532,'a_810']=np.nan\n",
    "    dfn.loc[dfn.a_860 >65532,'a_860']=np.nan\n",
    "    dfn.loc[dfn.a_450 >65532,'a_450']=np.nan\n",
    "    dfn.loc[dfn.a_500 >65532,'a_500']=np.nan\n",
    "    dfn.loc[dfn.a_550 >65532,'a_550']=np.nan\n",
    "    dfn.loc[dfn.a_570 >65532,'a_570']=np.nan\n",
    "    dfn.loc[dfn.a_600 >65532,'a_600']=np.nan\n",
    "    dfn.loc[dfn.a_650 >65532,'a_650']=np.nan\n",
    "    \n",
    "    dfn['ndvi_raw']=(dfn.a_760-dfn.a_680)/(dfn.a_760+dfn.a_680)\n",
    "    dfn.ndvi_raw.interpolate(method='pad',axis=0, inplace=True) #interpolation of missing data NaN\n",
    "    dfn.loc[dfn.ndvi_raw <0,'ndvi_raw']=0\n",
    "    dfn['ndvi']=dfn.loc[0:len(dfn),'ndvi_raw'].rolling(window=4).mean() # rolling mean of interpolated data\n",
    "    \n",
    "    dfn['green_red_raw']=(dfn.a_570-dfn.a_680)/(dfn.a_570+dfn.a_680)\n",
    "    dfn.green_red_raw.interpolate(method='pad',axis=0, inplace=True) #interpolation of missing data NaN\n",
    "    dfn.loc[dfn.green_red_raw <0,'green_red_raw']=0\n",
    "    dfn['green_red']=dfn.loc[0:len(dfn),'green_red_raw'].rolling(window=4).mean() # rolling mean of interpolated data\n",
    "    \n",
    "\n",
    "\n",
    "url_proj= fc.selected_path\n",
    "\n",
    "    # Store mail parameters\n",
    "mail_list=mail_addr_to.value.split(',')\n",
    "data_mail=[mail_addr_from.value,mail_addr_to.value,mail_smtp.value,mail_port.value,mail_pw.value]\n",
    "\n",
    "if mail_store.value:\n",
    "    \n",
    "    with open (url_proj+'/'+'mail_params.csv','w') as f:\n",
    "               \n",
    "                data_writer = csv.writer(f, delimiter=',')\n",
    "                data_writer.writerow(data_mail)\n",
    "\n",
    "if mail_on.value and mail_pw.value =='':\n",
    "    \n",
    "    \n",
    "    with open (url_proj+'/'+'mail_params.csv','r') as f:\n",
    "        reader = csv.reader(f, delimiter=',')\n",
    "        data_mail = next(reader) \n",
    "\n",
    "\n",
    "    #READ THE CLOUD    \n",
    "\n",
    "flag_bat=1\n",
    "cloudID_tt=TT_cloud.value\n",
    "\n",
    "\n",
    "#TTcloud_tt=url_site+cloudID_tt\n",
    "\n",
    "cols=['timestamp','tree_talker', 'sap_flow_density','stem_humidity','radial_growth','ndvi','green_red','air_temperature','rel_air_humidity','trunk_axis_movement']\n",
    "\n",
    "#dfn_cum=pd.DataFrame(columns=cols) \n",
    "dfn_day=pd.DataFrame(columns=cols) \n",
    "\n",
    "d=dt.datetime.now()\n",
    "old_day=d.strftime('%d.%m.%Y')\n",
    "        \n",
    "        \n",
    "while True:\n",
    "  \n",
    "        \n",
    "        t0=time.time()\n",
    "        ts = str(int(time.time()))\n",
    "       \n",
    "       \n",
    "        \n",
    "        \n",
    "        while True :\n",
    "            try:\n",
    "                    print (\"job start at ... \",dt.datetime.now())\n",
    "                    url_tt = 'http://naturetalkers.altervista.org/'+cloudID_tt+'/ttcloud.txt'\n",
    "                    df_tt=pd.read_csv(url_tt, sep=',',engine='python',header=None)\n",
    "                    \n",
    "            except:\n",
    "                    print (\"altervista server failure .....\")\n",
    "                    time.sleep(6)\n",
    "                    pass\n",
    "            else:\n",
    "                    break\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "       \n",
    "        \n",
    "        \n",
    "        dtt=pd.read_csv(fc.selected, sep=',',index_col=False, engine='python',header=0)\n",
    "        dtt.ID=dtt.ID.astype(str)\n",
    "      \n",
    "        \n",
    "        print ('Data retrieval time seconds .....',time.time()-t0)\n",
    "        t1=time.time()\n",
    "               \n",
    "        #CREATE DATAFRAME FOR TT AND TT FIRE\n",
    "        \n",
    "        a=[]\n",
    "        col0=df_tt.iloc[:,0].to_list()\n",
    "        col1=df_tt.iloc[:,1].to_list() \n",
    "        for i in range (len(col1)):\n",
    "                a.append(col1[i].split(';'))\n",
    "        dfraw=pd.DataFrame(a)\n",
    "        df_tt=dfraw[480*31:len(dfraw)] # we take data after 240 hours of stabilizatio (10 days)\n",
    "        df_tt.reset_index(drop=True,inplace=True)\n",
    "        \n",
    "               \n",
    "               \n",
    "        \n",
    "        #TREE TALKER SECTION\n",
    "        \n",
    "        #CLEANING DATAFRAME GENERATING COMBINED STRING 49 AND 4D FOR ID of treetalkers\n",
    "        \n",
    "      \n",
    "        names_tt=dtt.ID\n",
    "        \n",
    "        \n",
    "        #dfn_cum.to_csv (url_names+'_'+day+'.csv',index=False)\n",
    "        df_Vbat=pd.DataFrame(columns=['ID','date','Vbat'])\n",
    "\n",
    "\n",
    "        for i in range (0,len(dtt)):\n",
    "                dfn_day=pd.DataFrame(columns=cols)\n",
    "                dfx=df_tt[df_tt.iloc[:,0]==names_tt[i]]\n",
    "                if len(dfx)==0:\n",
    "                    print (names_tt[i], 'missing')\n",
    "                    row_bat=[names_tt[i],old_day,'missing']                 \n",
    "                    df_Vbat.loc[len(df_Vbat)]=row_bat\n",
    "                    continue\n",
    "            \n",
    "                dfn1=dfx[dfx.iloc[:,2]=='4D']\n",
    "                col_delete=[1,2,21,22,23,24,25,26,27,28,29] \n",
    "                dfn1.drop(col_delete,axis=1,inplace =True)\n",
    "                col1=['tree_talker','timestamp','Tref_0','Theat_0','growth_sensor',\n",
    "                'adc_bandgap','bits','rel_air_humidity','air_temperature','g_zmean','g_zstd','g_ymean','g_ystd','g_xmean','g_xstd','Tref_1','Theat_1','freq','adc_Vbat']\n",
    "                dfn1.columns=col1\n",
    "                dfn1.drop_duplicates(subset=None, inplace=True)\n",
    "                dfn1.reset_index(drop=True, inplace=True)\n",
    "                \n",
    "                dfn2=dfx[dfx.iloc[:,2]=='49']\n",
    "                col_delete=[1,2,18,19,20,21,22,23,24,25,26,27,28,29] \n",
    "                dfn2.drop(col_delete,axis=1,inplace =True)\n",
    "                col2=['tree_talker','timestamp','a_610','a_680','a_730','a_760','a_810','a_860','a_450','a_500','a_550','a_570','a_600','a_650','integration_time','gain']\n",
    "                dfn2.columns=col2\n",
    "                dfn2.drop_duplicates(subset=None, inplace=True)\n",
    "                dfn2.reset_index(drop=True, inplace=True)\n",
    "                \n",
    "                dfn=pd.merge(dfn1,dfn2,on=['tree_talker','timestamp'])\n",
    "                dfn.drop_duplicates(subset=None, inplace=True)\n",
    "                dfn.reset_index(drop=True, inplace=True)\n",
    "                dfn.timestamp=dfn.timestamp.astype(int)\n",
    "                dfn.timestamp=round(dfn.timestamp/10)*10\n",
    "                for j in dfn.columns[2:32]:\n",
    "                    dfn[j]=dfn[j].astype(float)\n",
    "               \n",
    "                dfn['timestamp']=dfn['timestamp'].astype(int)\n",
    "                dfn.to_csv(url_proj+'/'+names_tt[i]+'_raw.csv',index=False)\n",
    "                transf()\n",
    "                dfn.to_csv(url_proj+'/'+names_tt[i]+'_transf.csv',index=False)\n",
    "                \n",
    "               \n",
    "                Vbat_show()\n",
    "                elab_sapflow()\n",
    "                elab_growth()\n",
    "                elab_stem_humidity()\n",
    "                elab_light()\n",
    "                \n",
    "                row_bat=[dfn.loc[len(dfn)-1,'tree_talker'],dfn.loc[len(dfn)-1,'date'],dfn.loc[len(dfn)-1,'Vbat_c']]          \n",
    "                df_Vbat.loc[len(df_Vbat)]=row_bat\n",
    "               \n",
    "                dfn.to_csv(url_proj+'/'+names_tt[i]+'_elab.csv',index=False)\n",
    "                \n",
    "                dfn_c=dfn[['tree_talker', 'timestamp','date','sap_flow_density','stem_humidity','radial_growth','ndvi','green_red','air_temperature','rel_air_humidity','trunk_axis_movement']]\n",
    "                dfn_c.reset_index(drop=True, inplace=True)\n",
    "                \n",
    "            \n",
    "                d=dt.datetime.now()\n",
    "                day=d.strftime('%d.%m.%Y')\n",
    "                last_date = pd.to_datetime(dfn_c.loc[len(dfn_c)-1,'timestamp'],unit='s')\n",
    "    \n",
    "                last_date=last_date.strftime('%d/%m/%Y/%H:%M:%S')\n",
    "                #dfn_c['date']=last_date\n",
    "                #dfn_cum.loc[len(dfn_cum)]=dfn_tot.loc[len(dfn_tot)-1]\n",
    "                \n",
    "               \n",
    "                dfn_day.loc[len(dfn_day)]=dfn_c.loc[len(dfn_c)-1]\n",
    "                \n",
    "                file_day =url_proj+'/'+cloudID_tt+'_'+day\n",
    "                if os.path.exists(file_day+'.csv'):\n",
    "                    bol=False\n",
    "                else:\n",
    "                    bol=True\n",
    "                with open(file_day+'.csv','a+') as f:\n",
    "                           dfn_day.to_csv(f,index=False,header=bol)\n",
    "                \n",
    "              \n",
    "                \n",
    "        \n",
    "        \n",
    "                \n",
    "      \n",
    "        df_Vbat.to_csv(url_proj+'/'+cloudID_tt+'_BAT_'+day+'.csv',index=False)\n",
    "        \n",
    "        if (day != old_day or flag_bat==1) and mail_on.value:# flag 1 only when you start script for the first time\n",
    "            Vbat_mail()\n",
    "            old_day=day\n",
    "            flag_bat=0\n",
    "       \n",
    "        \n",
    "     \n",
    "        print ('TT total elaboration time seconds .....',time.time()-t0)\n",
    "        \n",
    "        \n",
    "        \n",
    "       \n",
    "        if loop_on.value:\n",
    "            time.sleep(time_cycle.value)\n",
    "        else:\n",
    "            print ('job ended')\n",
    "            break\n",
    "            \n",
    "        print('Waiting next job .......')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip freeze > requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
